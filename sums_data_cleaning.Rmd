---
title: "KidsAIR initial SUMs data work"
author: "Ethan Walker"
date: "Started 23 Dec 2019, Updated 6 Feb 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(readxl)
library(naniar)
library(lubridate)
library(zoo)
library(knitr)
jv_palette <- c("#330099","#CC0066","#FF6633", 
                 "#0099CC", "#FF9900","#CC6633",
                  "#FF3366", "#33CC99", "#33999")
```

# Add linked IDs to WMT SUMs data logs
## Use these throughout the data cleaning process to check start times
## Files and notes can be found on Box: 
### NoonanGroupData > KidsAIR > Ethan - data cleaning and analysis
```{r}
# Input file from Box: ibutton.xlsx
wmt_sums_data_log <- read_csv("Input/WMT/wmt_sums_data_log.csv") %>%
  mutate(home_winter_id = as.character(HomeWinterID),
         ibid = iButtonID,
         date_log = InstallDate,
         time_log = InstallTime) %>% 
  select(home_winter_id, ibid, date_log, time_log)

kids_linked_ids <- read_rds("Output/kids_linked_ids.rds") %>% 
  filter(area == "WMT") %>% 
  select(home_winter_id, winter_id, home, home_id) 

wmt_sums_log <- wmt_sums_data_log %>% 
  left_join(kids_linked_ids, by = "home_winter_id") %>% 
  select(home_winter_id, winter_id, home, home_id, date_log, time_log, ibid) %>% 
  arrange(home, date_log) %>% 
  mutate(date_log = mdy(date_log))
  
write_rds(wmt_sums_log, "Output/wmt_sums_data_log.rds")
write_csv(wmt_sums_log, "Output/wmt_sums_data_log.csv")


# Input file from Box: ibuttonupd.xlsx
wmt_sums_data_log_updated <- read_csv("Input/WMT/wmt_sums_data_log_updated.csv") %>% 
  mutate(home_winter_id = as.character(HomeWinterID),
         date = ChangeDate,
         time = ChangeTime,
         alarms = Alarms,
         file_name = ibutFile,
         notes = `REPLACE(REPLACE(Notes`) %>% 
  select(home_winter_id, date, time, alarms, file_name, notes)

wmt_sums_log <- wmt_sums_data_log_updated %>% 
  left_join(kids_linked_ids, by = "home_winter_id") %>% 
  select(home_winter_id, home, home_id, date, time, alarms, file_name, notes) %>% 
  arrange(home, date)

write_csv(wmt_sums_log, "Output/wmt_sums_data_log_updated.csv")
```

# Add linked IDs to NN SUMs data logs
## Use these throughout the data cleaning process to check start times
## Files and notes can be found on Box: 
### NoonanGroupData > KidsAIR > Ethan - data cleaning and analysis
```{r}
# Input file from Box: ibutton.xlsx
nn_sums_data_log <- read_xlsx("Input/NN/nn_sums_data_log.xlsx") %>% 
  mutate(home_winter_id = as.character(HomeWinterID),
         ibid = iButtonID,
         date_log = InstallDate,
         time_log = InstallTime) %>% 
  select(home_winter_id, ibid, date_log, time_log)

kids_linked_ids <- read_rds("Output/kids_linked_ids.rds") %>% 
  filter(area == "NN") %>% 
  select(home_winter_id, winter_id, home, home_id) 

nn_sums_log <- nn_sums_data_log %>% 
  left_join(kids_linked_ids, by = "home_winter_id") %>% 
  select(home_winter_id, winter_id, home, home_id, date_log, time_log, ibid) %>% 
  arrange(home, date_log) %>% 
  separate(time_log, c("trash", "time_log"), sep = " ") %>% 
  select(-trash)
  
write_rds(nn_sums_log, "Output/nn_sums_data_log.rds")
write_csv(nn_sums_log, "Output/nn_sums_data_log.csv")


# Input file from Box: ibuttonupd.xlsx
nn_sums_data_log_updated <- read_xlsx("Input/NN/nn_sums_data_log_updated.xlsx") %>% 
  mutate(home_winter_id = as.character(HomeWinterID),
         date = ChangeDate,
         time = ChangeTime,
         alarms = Alarms,
         file_name = ibutFile,
         notes = IgnoreReason) %>% 
  select(home_winter_id, date, time, alarms, file_name, notes)

nn_sums_log <- nn_sums_data_log_updated %>% 
  left_join(kids_linked_ids, by = "home_winter_id") %>% 
  select(home_winter_id, home, home_id, date, time, alarms, file_name, notes) %>% 
  arrange(home, date)

write_csv(nn_sums_log, "Output/nn_sums_data_log_updated.csv")
```

# Add linked IDs to AK SUMs data logs
## Use these throughout the data cleaning process to check start times
## Files and notes can be found on Box: 
### NoonanGroupData > KidsAIR > Ethan - data cleaning and analysis
```{r}
# Input file from Box: ibutton.xlsx
ak_sums_data_log <- read_xlsx("Input/AK/ak_sums_data_log.xlsx") %>% 
  mutate(home_winter_id = as.character(HomeWinterID),
         ibid = iButtonID,
         date_log = InstallDate,
         time_log = InstallTime) %>% 
  separate(time_log, c("trash", "time_log"), sep = " ") %>% 
  select(home_winter_id, ibid, date_log, time_log)

kids_linked_ids <- read_rds("Output/kids_linked_ids.rds") %>% 
  filter(area == "AK") %>% 
  select(home_winter_id, winter_id, home, home_id) 

ak_sums_log <- ak_sums_data_log %>% 
  left_join(kids_linked_ids, by = "home_winter_id") %>% 
  select(home_winter_id, winter_id, home, home_id, date_log, time_log, ibid) %>% 
  arrange(home, date_log)
  
write_csv(ak_sums_log, "Output/ak_sums_data_log.csv")
write_rds(ak_sums_log, "Output/ak_sums_data_log.rds")


# Input file from Box: ibutton.xlsx
ak_sums_data_log_updated <- read_xlsx("Input/AK/ak_sums_data_log_updated.xlsx") %>% 
  mutate(home_winter_id = as.character(HomeWinterID),
         date = ChangeDate,
         time = ChangeTime,
         alarms = Alarms,
         file_name = ibutFile,
         notes = IgnoreReason) %>% 
  select(home_winter_id, date, time, alarms, file_name, notes)

ak_sums_log <- ak_sums_data_log_updated %>% 
  left_join(kids_linked_ids, by = "home_winter_id") %>% 
  select(home_winter_id, home, home_id, date, time, alarms, file_name, notes) %>% 
  arrange(home, date)

write_csv(ak_sums_log, "Output/ak_sums_data_log_updated.csv")
```

# Initial load, format, and save KidsAIR WMT SUMs data
## Files were downloaded from Box: KidsAIR > 2019-Nov-Data > WMT > uploads > IButton
## Files were not named consistently, so I renamed them by their home ID number.
## Files also had several different types and formats.
## Manual cleaning of some files had to be done to get them in 
## consistent formats and file types to work with in R.
## Unfortunately, this process had to be manual due to the large number of files
## and inconsistent QC process across the various files.
## As a result, this process will be difficult to replicate if needed;
## The code below will highlight how the files were formatted and grouped together.
## Once files were in consistent formats, I load them to R in batches, as seen below.
## The following code cleans and combines all SUMs temperature data
## Notes and cleaned data files are uploaded to Box:
### KidsAIR > Ethan - data cleaning and analysis
```{r}
##### Read in sums csv files (from WMT) #####

# List files
## These files were directly exported by me from the Logtag software.
## I am confident in their formatting and content since I pulled the data
## from the original file type of the field instrument.
## The files have 5 columns: line, date, time, temp (C), notes
list_csv_files <- list.files("Input/WMT/sums_csv_new")

# Set working directory and load files in list; extract file name and add as column
## run next 13 lines together
setwd("Input/WMT/sums_csv_new") # set new working directory
initial_data = tibble(file_list = list_csv_files) %>% # use list of files from above
  extract(file_list, "home", remove = FALSE) %>% # extract file name, name "home"
  # apply read_csv function; name and format columns
  mutate(save_data = lapply(file_list, read_csv, skip = 1, 
                            col_names = c("line", "date", "time", "temp_c", "trash"),
                            col_types = cols(line = col_double(),
                                             date = col_date(format = ""),
                                             time = col_time(format = ""),
                                             temp_c = col_character(),
                                             trash = col_character()))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_csv <- initial_data %>% 
  mutate(area = "WMT",
         home2 = "WMA") %>% 
  unite("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  filter(temp_c != "Paused") %>% 
  # separate temp to remove instances of ">" in the temp data
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         file_type = "logtag") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
## Only 1 file had this format: 
## a 21 row header, then columns of datetime and temp (C)
list_csv_files_2 <- list.files("Input/WMT/sums_csv_old/format_1")

# Set working directory and load files in list; extract file name and add as column
## run next 9 lines together
setwd("Input/WMT/sums_csv_old/format_1")
initial_data = tibble(file_list = list_csv_files_2) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_csv, skip = 22,
                            col_names = c("datetime_sums", "temp_c"),
                            col_types = cols(datetime_sums = col_character(),
                                             temp_c = col_character()))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_csv_2 <- initial_data %>% 
  mutate(area = "WMT",
         home2 = "WMA",
         datetime_sums = ymd_hms(datetime_sums)) %>% 
  separate("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums),
         date_sums = ymd(date_sums),
         time_sums = hms(time_sums),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         file_type = "temp_c") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
## Numerous files had this format: 
## 5 columns: line, date, time, temp (F), notes
list_csv_files_3 <- list.files("Input/WMT/sums_csv_old/format_2")

# Set working directory and load files in list; extract file name and add as column
## run next 12 lines together
setwd("Input/WMT/sums_csv_old/format_2")
initial_data = tibble(file_list = list_csv_files_3) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_csv, skip = 2,
                            col_names = c("line", "date", "time", "temp_f", "trash"),
                            col_types = cols(line = col_double(),
                                             date = col_character(),
                                             time = col_time(format = ""),
                                             temp_f = col_character(),
                                             trash = col_character()))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_csv_3 <- initial_data %>% 
  mutate(area = "WMT",
         home2 = "WMA") %>% 
  unite("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  filter(temp_f != "Paused") %>% 
  separate(temp_f, c("trash2", "temp_f"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = mdy_hms(datetime),
         date_sums = mdy(date),
         time_sums = hms(time),
         temp_f = if_else(is.na(temp_f), trash2, temp_f),
         temp_f = as.numeric(temp_f),
         temp_c_sums = (temp_f-32)/1.8,
         file_type = "temp_f") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums),
         date_sums = ymd(date_sums)) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


##### Read in sums xlsx files (from WMT) #####

# List files
## Numerous files had this format with a 16 row header
## 2 columns: datetime, temp (C)
list_xlsx_files <- list.files("Input/WMT/sums_xlsx_files/header_skip16")

# Set working directory and load files in list; extract file name and add as column
## run next 6 lines together
setwd("Input/WMT/sums_xlsx_files/header_skip16")
initial_data = tibble(file_list = list_xlsx_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_xlsx, skip = 16)) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_xlsx <- initial_data %>% 
  mutate(datetime = ymd_hms(`Log data: date/time`),
         temp_c = as.numeric(`Temperature °C`),
         area = "WMT",
         home2 = "WMA") %>% 
  separate("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         home = as.factor(home),
         file_type = "xlsx_c") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums) 


# List files
## 6 files had this format with a 21 row header
## 2 columns: datetime, temp (C)
list_xlsx_files <- list.files("Input/WMT/sums_xlsx_files/header_skip21")

# Set working directory and load files in list; extract file name and add as column
## run next 6 lines together
setwd("Input/WMT/sums_xlsx_files/header_skip21")
initial_data = tibble(file_list = list_xlsx_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_xlsx, skip = 21)) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_xlsx2 <- initial_data %>% 
  mutate(datetime = ymd_hms(`Log data: date/time`),
         temp_c = as.numeric(`Temperature °C`),
         area = "WMT",
         home2 = "WMA") %>% 
  separate("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>%
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         home = as.factor(home),
         file_type = "xlsx_c") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
## Numerous files had this format with no header
## 2 columns: datetime, temp (C)
list_xlsx_files <- list.files("Input/WMT/sums_xlsx_files/no_header_2col_c")

# Set working directory and load files in list; extract file name and add as column
## run next 6 lines together
setwd("Input/WMT/sums_xlsx_files/no_header_2col_c")
initial_data = tibble(file_list = list_xlsx_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_xlsx)) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_xlsx3 <- initial_data %>% 
  mutate(datetime = ymd_hms(datetime),
         temp_c = as.numeric(temp_c),
         area = "WMT",
         home2 = "WMA") %>% 
  separate("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>%
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         home = as.factor(home),
         file_type = "xlsx_c") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
## Numerous files had this format with no header
## 4 columns: date, time, am/pm, temp (C)
list_xlsx_files <- list.files("Input/WMT/sums_xlsx_files/no_header_4col_c")

# Set working directory and load files in list; extract file name and add as column
## run next 6 lines together
setwd("Input/WMT/sums_xlsx_files/no_header_4col_c")
initial_data = tibble(file_list = list_xlsx_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_xlsx)) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_xlsx4 <- initial_data %>% 
  mutate(temp_c = as.numeric(temp_c),
         area = "WMT",
         home2 = "WMA") %>% 
  separate("time", c("trash", "time"), sep = " ") %>%
  unite("time", c("time", "am_pm"), sep = " ") %>%
  unite("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>%
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         home = as.factor(home),
         file_type = "xlsx_c") %>% 
  select(home, area, datetime_sums, temp_c_sums, file_type) %>% 
  separate("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums),
         date_sums = ymd(date_sums),
         time_sums = hms(time_sums)) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
## Numerous files had this format with no header
## 4 columns: date, time, am/pm, temp (F)
list_xlsx_files <- list.files("Input/WMT/sums_xlsx_files/no_header_4col_f")

# Set working directory and load files in list; extract file name and add as column
## run next 6 lines together
setwd("Input/WMT/sums_xlsx_files/no_header_4col_f")
initial_data = tibble(file_list = list_xlsx_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_xlsx)) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
wmt_sums_xlsx5 <- initial_data %>% 
  mutate(temp_f = as.numeric(temp_f),
         area = "WMT",
         home2 = "WMA") %>% 
  separate("time", c("trash", "time"), sep = " ") %>%
  unite("time", c("time", "am_pm"), sep = " ") %>% 
  unite("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  unite("home", c("home2", "home"), sep = "") %>% 
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c_sums = (temp_f-32)/1.8,
         home = as.factor(home),
         file_type = "xlsx_f") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  separate("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums),
         date_sums = ymd(date_sums),
         time_sums = hms(time_sums)) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  arrange(home, datetime_sums)


# Bind all WMT SUMs data together
wmt_sums_raw <- rbind(wmt_sums_csv, wmt_sums_csv_2, wmt_sums_csv_3,
                      wmt_sums_xlsx, wmt_sums_xlsx2, wmt_sums_xlsx3,
                      wmt_sums_xlsx4, wmt_sums_xlsx5) %>% 
  filter(!is.na(datetime_sums)) %>% 
  mutate(file_type = factor(file_type, levels = c("logtag", "temp_c",
                                                  "temp_f", "xlsx_c",
                                                  "xlsx_f"))) %>% 
  arrange(home, datetime_sums, file_type) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  arrange(home, datetime_sums)


# write_rds(wmt_sums_raw, "Output/wmt_sums_raw.rds")
```

# Initial load, format, and save KidsAIR NN SUMs data
## This chunk performs the same process that was done previously for WMT files
```{r}
##### Read in sums csv files (from NN) #####

# List files
## These files were directly exported by me from the Logtag software.
## I am confident in their formatting and content since I pulled the data
## from the original file type of the field instrument.
## The files have 5 columns: line, date, time, temp (C), notes
list_csv_files <- list.files("Input/NN/sums_csv_new")

# Set working directory and load files in list; extract file name and add as column
## run next 12 lines together
setwd("Input/NN/sums_csv_new")
initial_data = tibble(file_list = list_csv_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_csv,
                            col_names = c("line", "date", "time", "temp_c", "trash"),
                            col_types = cols(line = col_character(),
                                             date = col_date(format = ""),
                                             time = col_time(format = ""),
                                             temp_c = col_character(),
                                             trash = col_character()))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above
nn_sums_csv <- initial_data %>% 
  mutate(area = "NN") %>% 
  unite("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         file_type = "logtag") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
# 1 file had this format: No header, columns of datetime and temp (C)
list_csv_files_2 <- list.files("Input/NN/sums_csv_old/2col-c")

# Set working directory and load files in list; extract file name and add as column
## run next 7 lines together
setwd("Input/NN/sums_csv_old/2col-c")
initial_data = tibble(file_list = list_csv_files_2) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_csv)) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above; combine with other PM data below
nn_sums_csv_2 <- initial_data %>% 
  mutate(area = "NN",
         datetime_sums = mdy_hm(datetime)) %>% 
  separate("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>%
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums),
         date_sums = ymd(date_sums),
         time_sums = hms(time_sums),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         file_type = "temp_c") %>%
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums) 


# List files
## Numerous files had this format
## No header, 3 columns: date, time, temp (F)
##### NO LONGER USING THESE FILES!
##### COMPARED TO CORRESPONDING LOGTAG FILES, THE TIMESTAMPS ARE OFF
list_csv_files_3 <- list.files("Input/NN/sums_csv_old/3col-f")

# Set working directory and load files in list; extract file name and add as column
## run next 12 lines together
setwd("Input/NN/sums_csv_old/3col-f")
initial_data = tibble(file_list = list_csv_files_3) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_csv, skip = 1,
                            col_names = c("date", "time", "temp_f"),
                            col_types = cols(date = col_character(),
                                             time = col_time(format = ""),
                                             temp_f = col_character()))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above; combine with other PM data below
nn_sums_csv_3 <- initial_data %>% 
  mutate(area = "NN") %>% 
  unite("datetime", c("date", "time"), sep = " ", remove = FALSE) %>% 
  filter(temp_f != "Paused") %>% 
  separate(temp_f, c("trash2", "temp_f"), sep = " ", remove = FALSE) %>%
  mutate(datetime_sums = mdy_hms(datetime),
         date_sums = mdy(date),
         time_sums = time,
         temp_f = if_else(is.na(temp_f), trash2, temp_f),
         temp_f = as.numeric(temp_f),
         temp_c_sums = (temp_f-32)/1.8,
         file_type = "temp_f") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  distinct() %>% 
  filter(!is.na(temp_c_sums))



# Bind all WMT SUMs data together
nn_sums_raw <- rbind(nn_sums_csv, nn_sums_csv_2) %>% 
  filter(!is.na(datetime_sums)) %>% 
  mutate(file_type = factor(file_type, levels = c("logtag", "temp_c"))) %>% 
  arrange(home, datetime_sums, file_type) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  arrange(home, datetime_sums)
  

# write_rds(nn_sums_raw, "Output/nn_sums_raw.rds")
```

# Initial load, format, and save KidsAIR AK SUMs data
```{r}
##### Read in sums csv files (from AK) #####

# List files
## These files were directly exported by me from the Logtag software.
## I am confident in their formatting and content since I pulled the data
## from the original file type of the field instrument.
## The files have 5 columns: line, date, time, temp (C), notes
list_csv_files <- list.files("Input/AK/sums_csv_new")

# Set working directory and load files in list; extract file name and add as column
## run next 12 lines together
setwd("Input/AK/sums_csv_new")
initial_data = tibble(file_list = list_csv_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_csv,
                            col_names = c("line", "date", "time", "temp_c", "trash"),
                            col_types = cols(line = col_character(),
                                             date = col_date(format = ""),
                                             time = col_time(format = ""),
                                             temp_c = col_character(),
                                             trash = col_character()))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above; combine with other PM data below
ak_sums_csv <- initial_data %>% 
  mutate(area = "AK") %>% 
  unite("datetime", c("date", "time"), sep = " ", remove = FALSE) %>%
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime),
         date_sums = ymd(date),
         time_sums = hms(time),
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         file_type = "logtag") %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
## Numerous files had this format with no header
## 5 columns: line, date, time, temp (F), notes
##### NO LONGER USING THESE FILES!
##### COMPARED TO CORRESPONDING LOGTAG FILES, THE TIMESTAMPS ARE OFF
list_csv_files_2 <- list.files("Input/AK/sums_csv_old")

# Set working directory and load files in list; extract file name and add as column
## run next 7 lines together
setwd("Input/AK/sums_csv_old")
initial_data = tibble(file_list = list_csv_files_2) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_csv, skip = 1,
                            col_names = c("line", "date", "time", "temp_f", "trash"),
                            col_types = cols(line = col_character(),
                                             date = col_character(),
                                             time = col_time(format = ""),
                                             temp_f = col_character(),
                                             trash = col_character())))  %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above; combine with other PM data below
ak_sums_csv_2 <- initial_data %>% 
  mutate(area = "AK") %>% 
  filter(temp_f != "Paused") %>% 
  separate(temp_f, c("trash2", "temp_f"), sep = " ", remove = FALSE) %>%
  mutate(date_sums = mdy(date),
         time_sums = time,
         temp_f = if_else(is.na(temp_f), trash2, temp_f),
         temp_f = as.numeric(temp_f),
         temp_c_sums = (temp_f-32)/1.8,
         file_type = "temp_f") %>% 
  unite("datetime", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime)) %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  distinct() %>% 
  filter(!is.na(temp_c_sums))



##### Read in sums xlsx files (from AK) #####

# List files
## 3 files had this format with no header
## 5 columns: date, time, am or pm, C, temp
list_xlsx_files <- list.files("Input/AK/sums_xlsx_temp_c")

# Set working directory and load files in list; extract file name and add as column
## run next 6 lines together
setwd("Input/AK/sums_xlsx_temp_c")
initial_data = tibble(file_list = list_xlsx_files) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_xlsx,
                            col_names = c("date", "time", "am_pm", 
                                          "trash", "temp_c"))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above; combine with other PM data below
ak_sums_xlsx <- initial_data %>% 
  mutate(area = "AK") %>% 
  separate("time", c("trash", "time"), sep = " ", remove = FALSE) %>% 
  unite("time", c("time", "am_pm"), sep = " ") %>% 
  filter(temp_c != "Paused") %>% 
  separate(temp_c, c("trash2", "temp_c"), sep = " ", remove = FALSE) %>% 
  mutate(date_sums = ymd(date),
         time_sums = time,
         temp_c = if_else(is.na(temp_c), trash2, temp_c),
         temp_c_sums = as.numeric(temp_c),
         home = as.factor(home),
         file_type = "xlsx_c") %>% 
  unite("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums)) %>% 
  separate("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  mutate(date_sums = ymd(date_sums),
         time_sums = hms(time_sums)) %>% 
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# List files
## Numerous files had this format with no header
## 5 columns: date, time, am or pm, F, temp
list_xlsx_files2 <- list.files("Input/AK/sums_xlsx_temp_f")

# Set working directory and load files in list; extract file name and add as column
## run next 6 lines together
setwd("Input/AK/sums_xlsx_temp_f")
initial_data = tibble(file_list = list_xlsx_files2) %>%
  extract(file_list, "home", remove = FALSE) %>%
  mutate(save_data = lapply(file_list, read_xlsx,
                            col_names = c("date", "time", "am_pm", 
                                          "trash", "temp_f"))) %>%
  unnest(save_data) %>%
  select(-file_list) 

# Format combined file from above; combine with other PM data below
ak_sums_xlsx2 <- initial_data %>% 
  mutate(area = "AK") %>% 
  separate("time", c("trash", "time"), sep = " ", remove = FALSE) %>% 
  unite("time", c("time", "am_pm"), sep = " ") %>% 
  mutate(date_sums = ymd(date),
         time_sums = time,
         temp_c_sums = as.numeric((temp_f-32)/1.8),
         home = as.factor(home),
         file_type = "xlsx_f") %>% 
  unite("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums)) %>% 
  separate("datetime_sums", c("date_sums", "time_sums"), sep = " ", remove = FALSE) %>% 
  mutate(date_sums = ymd(date_sums),
         time_sums = hms(time_sums)) %>%
  select(home, area, datetime_sums, date_sums, time_sums, temp_c_sums, file_type) %>% 
  arrange(home, datetime_sums) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  filter(!is.na(temp_c_sums)) %>% 
  arrange(home, datetime_sums)


# Bind all AK SUMs data together
ak_sums_raw <- rbind(ak_sums_csv,  
                     ak_sums_xlsx, ak_sums_xlsx2) %>% 
  filter(!is.na(datetime_sums)) %>% 
  mutate(file_type = factor(file_type, levels = c("logtag",
                                                  "xlsx_c", "xlsx_f"))) %>% 
  arrange(home, datetime_sums, file_type) %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>%  # remove duplicate lines that have same info from different files
  ungroup() %>% 
  arrange(home, datetime_sums)  
  

# write_rds(ak_sums_raw, "Output/ak_sums_raw.rds")
```

# Bind all SUMs files together after initial upload
```{r}
wmt_sums_raw <- read_rds("Output/wmt_sums_raw.rds") 

nn_sums_raw <- read_rds("Output/nn_sums_raw.rds")

ak_sums_raw <- read_rds("Output/ak_sums_raw.rds")

all_sums_raw <- rbind(wmt_sums_raw, nn_sums_raw, ak_sums_raw)

# write_rds(all_sums_raw, "Output/all_sums_raw.rds")
```

# Check sample start times vs log start times
## This chunk of code produced a log of sample start times for each home
## that we have SUMs/Logtag/IButton data for.
## I used this log to go through individual homes and assess start times
## vs expected start times, find missing start times, etc.
## This log, with additional notes, are found on Box:
### KidsAIR > Ethan - data cleaning and analysis > sums_time_comparison
```{r}
# Load all SUMs data 
all_sums_raw <- read_rds("Output/all_sums_raw.rds") %>% 
  ungroup() %>% 
  arrange(area, home, datetime_sums)

# Load SUMs data logs
wmt_sums_log <- read_rds("Output/wmt_sums_data_log.rds")
nn_sums_log <- read_rds("Output/nn_sums_data_log.rds")
ak_sums_log <- read_rds("Output/ak_sums_data_log.rds")

# Combine SUMs logs from all areas
all_sums_log <- rbind(wmt_sums_log, nn_sums_log, ak_sums_log) %>% 
  mutate(winter_id = as.character(winter_id))

# Combine SUMs logs and data
## Get ready to compare start times from logs and data files
sums_time_comparison <- all_sums_raw %>%
  group_by(area, home) %>% 
  mutate(datetime_initial = first(datetime_sums)) %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums),
         datetime_initial = ymd_hms(datetime_initial),
         winter_id = if_else((datetime_sums - datetime_initial) > 20736000,
                             2, 1), 
         winter_id = as.character(winter_id)) %>% 
  ungroup() %>% 
  left_join(all_sums_log, by = c("home", "winter_id")) %>% 
  group_by(home, winter_id) %>% 
  unite(datetime_log, c("date_log", "time_log"), 
        sep = " ", remove = FALSE) %>% 
  mutate(datetime_log = ymd_hms(datetime_log),
         datetime_initial = first(datetime_sums),
         time_diff_sums = datetime_initial - datetime_log) %>% 
  distinct(time_diff_sums, .keep_all = TRUE) %>%
  ungroup() %>% 
  arrange(home, winter_id)

write_csv(sums_time_comparison, "Output/sums_time_comparison.csv")
write_rds(sums_time_comparison, "Output/sums_time_comparison.rds")
```

# Compile start and stop times for SUMs based on field logs
## Start times were compiled based on the beginning of data collection
## recorded in the paper logs. A list of start times is uploaded to Box:
### KidsAIR > Ethan - data cleaning and analysis > sums_time_comparison
## Stope times were based on the date of the final visit to a home each winter
## This timestamp was extracted from the "medicalvisit" files found on Box
```{r}
# Load all SUMs data
all_sums_raw <- read_rds("Output/all_sums_raw.rds") %>% 
  ungroup() %>% 
  arrange(area, home, datetime_sums)

# Load and format SUMs data logs for WMT

wmt_sums_stop <- read_csv("Input/WMT/wmt_medicalvisit_20200107.csv") %>% 
  mutate(home_winter_id = HomeWinterID,
         final_visit_date = if_else(VisitDate == "11/4/2025", "11/4/2015", VisitDate),
         final_visit_date = mdy(final_visit_date)) %>% 
  group_by(home_winter_id) %>% 
  arrange(final_visit_date) %>% 
  mutate(date_last = last(final_visit_date),
         date_filter = if_else(date_last == final_visit_date, 1, 0)) %>% 
  ungroup() %>% 
  filter(date_filter == 1) %>% 
  select(home_winter_id, final_visit_date) %>% 
  distinct(.keep_all = TRUE) %>% 
  arrange(home_winter_id) %>% 
  mutate(time = "01:00:00") %>% 
  unite(datetime_stop, c("final_visit_date", "time"), sep = " ") %>% 
  mutate(datetime_stop = ymd_hms(datetime_stop))

wmt_sums_start <- read_xlsx("Input/WMT/wmt_sums_start_times_20200107.xlsx") %>% 
  mutate(datetime_start = ymd_hms(datetime_start))

wmt_sums_start_stop <- wmt_sums_start %>% 
  left_join(wmt_sums_stop, by = "home_winter_id")

wmt_sums_raw <- all_sums_raw %>% 
  filter(area == "WMT") %>% 
  left_join(wmt_sums_start_stop, by = c("area", "home")) %>% 
  mutate(filter_var = 
         if_else(datetime_sums > datetime_start & datetime_sums < datetime_stop,
                 1, 0))

wmt_sums_filtered <- wmt_sums_raw %>% 
  filter(filter_var == 1) %>% 
  arrange(area, home, winter_id, datetime_sums) 

# write_rds(wmt_sums_filtered, "Output/wmt_sums_filtered.rds")

  
#####

nn_sums_stop <- read_xlsx("Input/NN/nn_medicalvisit_20200108.xlsx") %>% 
  mutate(home_winter_id = HomeWinterID,
         final_visit_date = ymd(VisitDate)) %>% 
  group_by(home_winter_id) %>% 
  arrange(final_visit_date) %>% 
  mutate(date_last = last(final_visit_date),
         date_filter = if_else(date_last == final_visit_date, 1, 0)) %>% 
  ungroup() %>% 
  filter(date_filter == 1) %>% 
  select(home_winter_id, final_visit_date) %>% 
  distinct(.keep_all = TRUE) %>% 
  arrange(home_winter_id) %>% 
  mutate(time = "01:00:00") %>% 
  unite(datetime_stop, c("final_visit_date", "time"), sep = " ") %>% 
  mutate(datetime_stop = ymd_hms(datetime_stop))

nn_sums_start <- read_xlsx("Input/NN/nn_sums_start_times_20200108.xlsx") %>% 
  mutate(datetime_start = ymd_hms(datetime_start))

nn_sums_start_stop <- nn_sums_start %>% 
  left_join(nn_sums_stop, by = "home_winter_id")

nn_sums_raw <- all_sums_raw %>% 
  filter(area == "NN") %>% 
  left_join(nn_sums_start_stop, by = c("area", "home")) %>% 
  mutate(filter_var = 
         if_else(datetime_sums > datetime_start & datetime_sums < datetime_stop,
                 1, 0))

nn_sums_filtered <- nn_sums_raw %>% 
  filter(filter_var == 1) %>% 
  arrange(area, home, winter_id, datetime_sums)

# write_rds(nn_sums_filtered, "Output/nn_sums_filtered.rds")


#####

ak_sums_stop <- read_xlsx("Input/AK/ak_medicalvisit_20200108.xlsx") %>% 
  mutate(home_winter_id = HomeWinterID,
         final_visit_date = ymd(VisitDate)) %>% 
  group_by(home_winter_id) %>% 
  arrange(final_visit_date) %>% 
  mutate(date_last = last(final_visit_date),
         date_filter = if_else(date_last == final_visit_date, 1, 0)) %>% 
  ungroup() %>% 
  filter(date_filter == 1) %>% 
  select(home_winter_id, final_visit_date) %>% 
  distinct(.keep_all = TRUE) %>% 
  arrange(home_winter_id) %>% 
  mutate(time = "01:00:00") %>% 
  unite(datetime_stop, c("final_visit_date", "time"), sep = " ") %>% 
  mutate(datetime_stop = ymd_hms(datetime_stop))

ak_sums_start <- read_xlsx("Input/AK/ak_sums_start_times_20200108.xlsx") %>% 
  mutate(datetime_start = ymd_hms(datetime_start))

ak_sums_start_stop <- ak_sums_start %>% 
  left_join(ak_sums_stop, by = "home_winter_id")

ak_sums_raw <- all_sums_raw %>% 
  filter(area == "AK") %>%
  left_join(ak_sums_start_stop, by = c("area", "home")) %>% 
  mutate(filter_var = 
         if_else(datetime_sums > datetime_start & datetime_sums < datetime_stop,
                 1, 0))

ak_sums_filtered <- ak_sums_raw %>% 
  filter(filter_var == 1) %>% 
  arrange(area, home, winter_id, datetime_sums)

# write_rds(ak_sums_filtered, "Output/ak_sums_filtered.rds")
```

# Checking to make sure multiple observations per datetime_sums were removed
# Number of obs in each dataset below should match # obs in check_dates
```{r}
wmt_sums_filtered <- read_rds("Output/wmt_sums_filtered.rds")
nn_sums_filtered <- read_rds("Output/nn_sums_filtered.rds")
ak_sums_filtered <- read_rds("Output/ak_sums_filtered.rds")

check_dates <- wmt_sums_filtered %>% 
  group_by(home) %>% 
  distinct(datetime_sums, .keep_all = TRUE)
```

# Combine filtered data from each area
```{r}
wmt_sums_filtered <- read_rds("Output/wmt_sums_filtered.rds")
nn_sums_filtered <- read_rds("Output/nn_sums_filtered.rds")
ak_sums_filtered <- read_rds("Output/ak_sums_filtered.rds")

all_sums_filtered <- rbind(wmt_sums_filtered, nn_sums_filtered, ak_sums_filtered)

# write_rds(all_sums_filtered, "Output/all_sums_filtered.rds")
```

# Continue cleaning up SUMs data
```{r}
all_sums_filtered <- read_rds("Output/all_sums_filtered.rds")
kids_linked_ids <- read_rds("Output/kids_linked_ids.rds") %>% 
  select(home_winter_id, area, treatment)


sums_clean <- all_sums_filtered %>% 
   mutate(temp_c_sums = as.numeric(temp_c_sums),
          winter_id = as.factor(winter_id),
          home_winter_id = as.character(home_winter_id),
          home_id = as.factor(home_id),
          day_of_week = weekdays(date_sums),
          month_sums = as.factor(month(date_sums, label = TRUE, abbr = TRUE))) %>% 
  select(-filter_var) %>% 
  arrange(area, home, winter_id, datetime_sums) %>% 
  left_join(kids_linked_ids, by = c("area", "home_winter_id"))
  

# write_rds(sums_clean, "Output/sums_clean.rds")


########## New cleaning on 6 Feb 2020 ##########

sums_clean <- read_rds("Output/sums_clean.rds")

# This cleaning is a bit of a desperation attempt to try and salvage most of the
# SUMs data. Because of the way data was collected and files were saved, it
# became very difficult ot piece files together for each home. For some of the homes,
# data is fine - particularly if they used LogTags for the entire Winter and there
# is one continuous file from one instrument for the whole Winter. However, if an
# IButton was used (which held only around 1 month of data), or if a LogTag was
# switched out during sampling, piecing the various files together becomes a nightmare.
# All of the files had heads and tails of pre- or post-sampling data that needed
# to be cut off, but there wasn't a good indication of when the sampling exactly
# stopped and started when an instrument was switched out in the field. There was
# typically overlap in the files when an instrument was switched out: a tail from
# the old instrument before it was turned off, and a head from the new instrument
# from the time it was turned on, but prior to sampling. During these overlap
# periods in the data, there was no good indication of what instrument was actually
# sampling within the home. I tried to write some rules/algorithms to pull out what
# I thought was the correct data, but there inconsistencies were inconsistent. 
# Nothing I did made the data seem trustworthy for most of the homes, so here I have
# resorted to cutting out those overlapping periods in the data. I am filtering out
# around 161,000 observations (of 3.5 million, so < 5% of the data), but I can't come
# up with any other way to have cleaned data that I actually trust, short of 
# pasting each individual file together by hand. Even then, there are formatting
# issues that would take days to resolve. So, this is the best way I have found
# to get what I think is reliable SUMs data: filtering out the observations
# with overlapping datapoints by pulling out instances when the time between
# sampling points is not consistent.

sums_new <- sums_clean %>% 
  group_by(area, home) %>% 
  mutate(time_diff = lead(datetime_sums) - datetime_sums,
         time_diff_indicator = if_else(time_diff != rollmean(time_diff, 4), 1, 0)) %>% 
  filter(time_diff_indicator != 1) %>%
  ungroup() %>% 
  arrange(area, home, winter_id, datetime_sums)

# write_rds(sums_new, "Output/sums_clean.rds")
```

# Plot temp over time for individual home to check for trends visually
```{r}
sums_clean <- read_rds("Output/sums_clean.rds")

sums_time_trends_plot <- sums_clean %>% 
  filter(home == "CH405") %>% 
  ggplot() + 
    geom_point(aes(datetime_sums, temp_c_sums, color = month_sums), size = 1.5) +
    theme_classic() +
    labs(y = "Temperature (degrees C)",
         x = "Datetime",
         color = "Logtag ID") +
    theme(axis.title.y = element_text(size = 12,
                                      margin = margin(t = 0, r = 20, b = 0, l = 0)),
          axis.title.x = element_text(size = 12),
          axis.text.x = element_blank(),
          axis.text.y = element_text(size = 12, color = "black"),
          axis.line.x = element_line(colour = "black", size = 1), 
          axis.line.y = element_line(colour = "black", size = 1), 
          axis.ticks = element_blank()) +
    scale_color_manual(values = jv_palette)
sums_time_trends_plot
```

# Check to see if there are missing files to search for
## Through 22 Jan 2020, all files are accounted for that are not documented as missing
## Update once data collection is finished in April 2020
```{r}
# Load SUMs data
sums_clean <- read_rds("Output/sums_clean.rds") 

check <- sums_clean %>% 
  filter(home_winter_id == 82 & area == "AK")

# Load SUMs data logs
wmt_sums_log <- read_rds("Output/wmt_sums_data_log.rds") %>% 
  mutate(area = "WMT")
nn_sums_log <- read_rds("Output/nn_sums_data_log.rds") %>% 
  mutate(area = "NN")
ak_sums_log <- read_rds("Output/ak_sums_data_log.rds") %>% 
  mutate(area = "AK")

# Combine SUMs logs from all areas
all_sums_log <- rbind(wmt_sums_log, nn_sums_log, ak_sums_log) %>% 
  mutate(winter_id = as.character(winter_id),
         sums_log = "true")  
  
sums_check <- sums_clean %>% 
  group_by(area, home, winter_id) %>% 
  distinct(home, .keep_all = TRUE) %>% 
  full_join(all_sums_log, by = c("area", "home", "winter_id")) %>% 
  ungroup() %>% 
  arrange(area, home, winter_id)

#write_csv(sums_check, "Output/sums_check.csv")
```

# Thresholds for heating events
```{r}
# Load SUMs data
sums_clean <- read_rds("Output/sums_clean.rds")


thresholds_test <- sums_clean %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums)) %>% 
  group_by(area, home, winter_id) %>%
  mutate(threshold_temp = if_else(temp_c_sums >= 40, 1, 0),
         threshold_temp_event = if_else(threshold_temp == 1 & lag(threshold_temp) == 0, 
                                        "start", "Temp < threshold"),
         threshold_temp_event = if_else(is.na(threshold_temp_event), "start", threshold_temp_event),
         threshold_temp_event = if_else(threshold_temp == 1 & threshold_temp_event == "Temp < threshold",
                                      "Temp >= threshold", threshold_temp_event),
         threshold_temp_event = if_else(threshold_temp_event == "Temp >= threshold" &
                                      lead(threshold_temp_event) == "Temp < threshold", 
                                      "event", threshold_temp_event)) %>% 
  filter(threshold_temp_event == "event" | threshold_temp_event == "start") %>% 
  spread(threshold_temp_event, datetime_sums) %>% 
  mutate(event = lead(event),
         time_diff_min = (event - start),
         time_diff_min = as.numeric(time_diff_min/60)) %>% 
  filter(!is.na(time_diff_min)) %>% 
  mutate(next_event = (lead(start)-event),
         next_event = as.numeric(next_event)/3600,
         event2 = if_else(next_event <= 1.5, lead(event), event),
         time_diff_min2 = (event - start),
         time_diff_min2 = as.numeric(time_diff_min2/60),
         event3 = if_else(next_event <= 1.5 & lead(next_event) <= 1.5, lead(event, 2), event2),
         time_diff_min3 = (event3 - start),
         time_diff_min3 = as.numeric(time_diff_min3/60)) %>% 
  distinct(event3, .keep_all = TRUE) %>% 
  mutate(time_diff_min4 = (event3 - start),
         time_diff_min4 = as.numeric(time_diff_min4/60)) %>% 
  filter(!is.na(time_diff_min4)) %>% 
  group_by(area, home, winter_id, date_sums) %>% 
  summarize(n = n(), mean_time = mean(time_diff_min4)) %>% 
  group_by(area) %>% 
  summarize("Mean events per day" = round(mean(n), digits = 2),
            "Mean event length (min)" = round(mean(mean_time), digits = 0))
thresholds_test


# Function for calculating heating events using specified threshold temps
# Also specify the "gap" time between events
# Try another function for % day above threshold
thresholds_function <- function(data, temp, gap) {

thresholds <- data %>% 
  mutate(datetime_sums = ymd_hms(datetime_sums)) %>% 
  group_by(area, home, winter_id) %>%
  mutate(threshold_temp = if_else(temp_c_sums >= temp, 1, 0),
         threshold_temp_event = if_else(threshold_temp == 1 & lag(threshold_temp) == 0, 
                                        "start", "Temp < threshold"),
         threshold_temp_event = if_else(is.na(threshold_temp_event), "start", threshold_temp_event),
         threshold_temp_event = if_else(threshold_temp == 1 & threshold_temp_event == "Temp < threshold",
                                      "Temp >= threshold", threshold_temp_event),
         threshold_temp_event = if_else(threshold_temp_event == "Temp >= threshold" &
                                      lead(threshold_temp_event) == "Temp < threshold", 
                                      "event", threshold_temp_event)) %>% 
  filter(threshold_temp_event == "event" | threshold_temp_event == "start") %>% 
  spread(threshold_temp_event, datetime_sums) %>% 
  mutate(event = lead(event),
         time_diff_min = (event - start),
         time_diff_min = as.numeric(time_diff_min/60)) %>% 
  filter(!is.na(time_diff_min)) %>% 
  mutate(next_event = (lead(start)-event),
         next_event = as.numeric(next_event)/3600,
         event2 = if_else(next_event <= gap, lead(event), event),
         time_diff_min2 = (event - start),
         time_diff_min2 = as.numeric(time_diff_min2/60),
         event3 = if_else(next_event <= gap & lead(next_event) <= gap, lead(event, 2), event2),
         time_diff_min3 = (event3 - start),
         time_diff_min3 = as.numeric(time_diff_min3/60)) %>% 
  distinct(event3, .keep_all = TRUE) %>% 
  mutate(time_diff_min4 = (event3 - start),
         time_diff_min4 = as.numeric(time_diff_min4/60)) %>% 
  filter(!is.na(time_diff_min4)) %>% 
  group_by(area, home, winter_id, date_sums) %>% 
  summarize(n = n(), mean_time = mean(time_diff_min4)) %>% 
  group_by(area) %>% 
  summarize("Mean events per day" = round(mean(n), digits = 2),
            "Mean event length (min)" = round(mean(mean_time), digits = 0))
thresholds

}

thresholds_function(sums_clean, 40, 2)


# Function to look at percentage of time spent above a threshold
thresholds_percent <- function(data, temp) {

thresholds <- data %>% 
  group_by(area, home, winter_id, date_sums) %>%
  mutate(threshold_temp = if_else(temp_c_sums >= temp, 1, 0)) %>% 
  summarize(percent_above = sum(threshold_temp)/n()*100) %>% 
  group_by(area) %>% 
  summarize("% time/day > threshold" = round(mean(percent_above), digits = 2))
thresholds

}

thresholds_percent(sums_clean, 40)
```

