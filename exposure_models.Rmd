---
title: "KidsAIR: exposure model"
author: "Ethan Walker"
date: "Started 19 March 2020, Updated 30 June 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      eval = TRUE, include = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(readxl)
library(naniar)
library(lubridate)
library(zoo)
library(lme4)
library(lmerTest)
library(pbkrtest)
library(emmeans)
library(broom)
library(MuMIn)
library(leaps)
library(glmnet)
jv_palette <- c("#330099","#CC0066","#FF6633", 
                 "#0099CC", "#FF9900","#CC6633",
                  "#FF3366", "#33CC99", "#33999")
```

```{r}
# Load individual datasets

file_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/KidsAIR/")

health_exposure_data_sampling_day <- 
  read_rds(paste0(file_path, "Output/health_exposure_data_sampling_day.rds")) 

exposure_analysis_data_long <- 
  read_rds(paste0(file_path, "Output/exposure_analysis_data_long_new.rds")) 

exposure_analysis_data_medium <- 
  read_rds(paste0(file_path, "Output/exposure_analysis_data_medium.rds")) 

exposure_analysis_data_short <- 
  read_rds(paste0(file_path, "Output/exposure_analysis_data_short.rds"))

sums_rolling_pm_data <- 
  read_rds(paste0(file_path, "Output/sums_rolling_pm_data.rds"))
```


```{r}
####### Format full data to use for analysis
analysis_data <- health_exposure_data_sampling_day %>% 
  filter(winter_id == 1 & treatment_assigned == "Placebo") %>% 
  arrange(area, home, sampling_day) %>% 
  distinct(home, .keep_all = TRUE) %>% 
  ungroup() %>% 
  # dichotomize variables by median value
  mutate(moisture_closest_2level = cut(moisture_closest, breaks = c(0, 10.5, 100),
                                 labels = c("<10.5", "10.5+"),
                                 right = FALSE),
         moisture_winter_2level = cut(mean_moisture_winter, breaks = c(0, 10.5, 100),
                                 labels = c("<10.5", "10.5+"),
                                 right = FALSE)) %>% 
  mutate(temp_max_2level = cut(temp_indoor_max, breaks = c(0, 30, 100),
                                 labels = c("<30", "30+"),
                                 right = FALSE),
         temp_min_2level = cut(temp_indoor_min, breaks = c(0, 16.5, 100),
                                 labels = c("<16.5", "16.5+"),
                                 right = FALSE),
         rh_max_2level = cut(rh_indoor_max, breaks = c(0, 40, 100),
                                 labels = c("<40", "40+"),
                                 right = FALSE),
         rh_min_2level = cut(rh_indoor_min, breaks = c(0, 20, 100),
                                 labels = c("<20", "20+"),
                                 right = FALSE)) %>% 
  mutate(sums_mean_sampling_period_5 = sums_mean_sampling_period/5,
         temp_perc_25_2level = cut(temp_perc_25, breaks = c(0, 50, 100),
                                 labels = c("<50", "50+"),
                                 right = FALSE),
         temp_perc_27_2level = cut(temp_perc_27, breaks = c(0, 35, 100),
                                 labels = c("<35", "35+"),
                                 right = FALSE),
         temp_perc_30_2level = cut(temp_perc_30, breaks = c(0, 10, 100),
                                 labels = c("<10", "10+"),
                                 right = FALSE)) %>% 
  mutate(home_act_door_2level = cut(home_act_door_sum, breaks = c(0, 1, 7),
                                 labels = c("<1", "1+"),
                                 right = FALSE),
         home_act_smoke_2level = cut(home_act_smoking_sum, breaks = c(0, 1, 7),
                                 labels = c("<1", "1+"),
                                 right = FALSE),
         home_act_windows_2level = cut(home_act_windows_sum, breaks = c(0, 1, 7),
                                 labels = c("<1", "1+"),
                                 right = FALSE),
         home_act_sweep_2level = cut(home_act_sweep_sum, breaks = c(0, 3, 7),
                                 labels = c("<3", "3+"),
                                 right = FALSE))
```

**Step 1**

The model selection process begins with simple associations between mean
PM2.5 over the 6-day sampling period and covariates in the dataset. See
the `exposure_covariate_associations.rmd` file for this process.

Variables that are associated with PM2.5 are selected and assessed for collinearity
in the `collinearity_exposure_analysis.rmd`. Variables that have high overlap
are selected out of the pool of potential covariates to parse down the options;
however, these variables can be used in sensitivity analyses later.

Initial variables to use for model selection (14):
Demographics: area, income_3level, residents_smoke
Home Characteristics: home_floors_2level, home_pets_2level, stove_cert, 
                      chimney_clean_3level, wood_collect_2level, 
Home Activity: home_act_door_2level, home_act_smoke_2level
Others: sums_events_sampling_period, mean_temp_sampling_period_5, 
        stove_grade_3level, moisture_closest_2level, amb_pm_sampling_period_5,

   
**Missing data notes**
Some vars (like residents_smoke), other demographics, and home activity vars
have quite a bit of missing data. This is in addition to the missing ambient
and SUMs data. The first step should be to account for as much of this as possible.
See if there are ways to pull demographic data from Winter 2.
Then, see if data for WMT is more complete in general. The idea is to minimize
missing data for model selection and the final model to have as many observations as
possible. 
Consider doing a more "full" model for WMT only (if there is less missing data),
particularly since the ambient data is more reliable for WMT than the other areas.
(ambient temp/PM data for WMT is based on geolocated lat/long, whereas NN and AK
are based on zipcode and have much less spatial variation).
Then you could justify not doing a mixed model, and model selection would be easier.
Then, using data from all areas, use the full model from WMT to work on a 
mixed model that is likely reduced due to sparse data from the other areas.
Since model selection is difficult with mixed models, use the WMT model to inform
this model, while also doing sensitivity analysis to check other variables.
Aside from the multivariable model, much of the paper could also be looking at
simple associations between PM and some of the novel covars (SUMS, ambient data,
stove grades, wood moisture), as well as methods for collecting and analysing 
those vars.
Also look into predict() function for teach/test and validating the model.
Discussion can focus on what important predictors of indoor PM are in these homes - 
if simple demographic data predicts as well as complex things like SUMs and wood
moisture, or if there is a spectrum of predictors and complexity in their collection.


**Looking at model selection and averaging after multiple imputation**

After assessing many model selection possibilities, using multiple imputation
and model selection from imputed datasets seems to be the best option.
There is not a huge amount of missing data, but it is spread out enough
that it eliminates a larger percentage of the homes from consideration for
model selection. Multiple imputation gives us a full dataset to work with,
and there are documented techniques of using this data for model selection.

Helpful manuals and vignettes:

https://cran.r-project.org/web/packages/mice/mice.pdf


First, select analysis variables
```{r}
library(mice)
#library(pan)
#library(multilevel)

# Select analysis vars
selected_vars <- analysis_data %>% 
  filter(area == "WMT") %>% 
  select(pm_mean_sampling_period, income_3level, 
         residents_smoke,
         home_floors_2level, home_sqft_2level,
         home_pets_2level,
         stove_age_3level, chimney_clean_3level, 
         wood_collect_2level,
         sums_events_sampling_period_7.5,
         mean_temp_sampling_period_5,
         amb_pm_sampling_period_5,
         stove_grade_3level,
         home_fireplace) %>% 
  mutate(log_pm_mean_sampling_period = log(pm_mean_sampling_period)) %>%  
  select(-pm_mean_sampling_period) 

  na.exclude()
  
  # Check % missing data
mean(is.na(selected_vars)) # 8% for WMT, 10% for NN, 16% for AK, 10% total
```

**Note**

When selecting data above, WMT has 63 observations
When use `na.exclude()` to only use complete data (what is needed for AIC selection),
the observations drops to 27. While there is only 8.4% missing data, it is spread
out enough that excluding it to have complete observations means we can only use
less than half for model selection. This would be a very biased version of model
selection to exclude that much data, which justifies multiple imputation to 
impute the 8.4% missing data and use that for model selection.
The missing observations are even more extreme for NN and AK.

Next, assess data structure and patterns of missing data
Document missing data thoroughly for manuscript
```{r}
# Look at structure of data and check variable types
str(selected_vars)

# Check % missing data
mean(is.na(selected_vars)) # 8.4% for WMT

# Using mice package

# Look for patterns in missing data
missing_patterns <- md.pattern(selected_vars)

missing_patterns

sum(missing_patterns[, "residents_smoke"] == 0)

hist(selected_vars$log_pm_mean_sampling_period)

# Check for distribution between vars and missingness - see if there are patterns
## No obvious patterns in the missing data
## Missing covars do not seem to be related to the outcomes

# Histogram
missing_hist <- selected_vars %>% 
  mutate(missing_var = if_else(is.na(residents_smoke), "missing yes", "missing no")) %>% 
  ggplot() +
    geom_bar(aes(log_pm_mean_sampling_period), color = "red") +
    facet_wrap(~missing_var) +
    theme_minimal()
missing_hist


# Summary Statistics
missing_summary <- selected_vars %>% 
  mutate(missing_var = if_else(is.na(stove_grade_3level), "missing yes", "missing no")) %>%
  group_by(area, missing_var) %>% 
  summarize(n = n(),
            mean_pm = mean(pm_mean_sampling_period, na.rm = TRUE), 
            sd_pm = sd(pm_mean_sampling_period, na.rm = TRUE),
            median_pm = median(pm_mean_sampling_period, na.rm = TRUE)) %>% 
  group_by(area) %>% 
  mutate(total_n = sum(n),
         perc_miss = n/total_n*100) %>% 
  select(area, missing_var, n, perc_miss, mean_pm, sd_pm, median_pm)
missing_summary
```

```{r}
# T-tests
missing_test <- selected_vars %>% 
  mutate(missing_var = if_else(is.na(stove_grade_3level), "missing yes", "missing no")) %>% 
  filter(!is.na(log_pm_mean_sampling_period) & !is.na(missing_var))


ak_data <- missing_test %>% 
  filter(area == "AK")

nn_data <- missing_test %>% 
  filter(area == "NN")

wmt_data <- missing_test %>% 
  filter(area == "WMT")

t.test(log_pm_mean_sampling_period ~ missing_var, data = ak_data)
t.test(log_pm_mean_sampling_period ~ missing_var, data = nn_data)
t.test(log_pm_mean_sampling_period ~ missing_var, data = wmt_data)


# Complete case vs missing data comparison
complete_case <- selected_vars %>% 
  na.exclude()

missing_summary <- complete_case %>% 
  group_by(area) %>% 
  summarize(n = n(),
            mean_var = mean(mean_temp_sampling_period_5, na.rm = TRUE), 
            sd_var = sd(mean_temp_sampling_period_5, na.rm = TRUE),
            median_var = median(mean_temp_sampling_period_5, na.rm = TRUE)) %>% 
  group_by(area) %>% 
  select(area, n, mean_var, sd_var, median_var)
missing_summary

missing_summary <- complete_case %>% 
  group_by(area, income_3level) %>% 
  summarize(n = n()) %>% 
  group_by(area) %>% 
  mutate(total_n = sum(n),
         perc = n/total_n*100) %>% 
  select(area, income_3level, n, perc, total_n)
missing_summary


missing_data <- selected_vars %>% 
  group_by(home) %>% 
  filter_at(vars(pm_mean_sampling_period:stove_grade_3level), any_vars(is.na(.)))

missing_summary <- missing_data %>% 
  group_by(area) %>% 
  summarize(n = n(),
            mean_var = mean(mean_temp_sampling_period_5, na.rm = TRUE), 
            sd_var = sd(mean_temp_sampling_period_5, na.rm = TRUE),
            median_var = median(mean_temp_sampling_period_5, na.rm = TRUE)) %>% 
  group_by(area) %>% 
  select(area, n, mean_var, sd_var, median_var)
missing_summary

missing_summary <- missing_data %>% 
  group_by(area, income_3level) %>% 
  summarize(n = n()) %>% 
  group_by(area) %>% 
  mutate(total_n = sum(n),
         perc = n/total_n*100) %>% 
  select(area, income_3level, n, perc, total_n)
missing_summary


# Check ICC 
multilevel::ICC1(aov(mean_temp_sampling_period_5 ~ area, data = selected_vars))
```


Next, use `mice()` to impute the missing data
Assess imputed data for summary stats and convergence
```{r}
# set seed to be able to replicate imputation
set.seed(123)

# Impute missing data; m = 10 datasets (check % missing data and match)
imputed_data <- mice(selected_vars, m=10, maxit = 40,
                     method = c("polr", "logreg", "logreg", "logreg", "logreg",
                                "polr", "polr", "logreg", "pmm",
                                "pmm", "pmm", "polr", "polr", "pmm"))

write_rds(imputed_data, paste0(file_path, "Output/imputed_exposure_data_2july2020.rds"))

imputed_exposure_data <- read_rds(paste0(file_path, "Output/imputed_exposure_data_2july2020.rds"))

# Compare imputed summary to original summary
summary(selected_vars)
summary(complete(imputed_exposure_data))

# Look at imputation methods for each var; consider changing
imputed_data$method

# Can add "long" or "broad" arguments
complete(imputed_exposure_data, "long")

# Sample one of the imputed datasets
check1 <- complete(imputed_data, 3)

densityplot(selected_vars$log_pm_mean_sampling_period)

# Use seed to get the exact same results from random sampling
# seed = 123

# See vignette #2 for setting up predictor matrices and relationships b/w vars

# Print predictor matrix
## Keep considering, but I don't see a reason to alter this as of now
imputed_data$pred

# Check for convergence
## In general, we would like the streams to intermingle and be free of any trends 
## at the later iterations.
plot(imputed_data)

# Check that the imputation method matches the data type correctly
## particularly for PM that should be log transformed, and the factors

stripplot(imputed_data)

# Can do regression on the imputed data - either pooled or individual datasets
```



The above seems to be a good method of imputing the missing data, so moving on 
to model selection/averaging

http://mami.r-forge.r-project.org/MAMI_manual.pdf 

```{r}
library(MAMI)

# Using MAMI package, perform model averaging and selection
## Will take ~20 to 30 mins with 5 iterations and bootstrap
model_ave <- mami(imputed_data, missing.data = "imputed", model = "gaussian",
                  outcome = "log_pm_mean_sampling_period", 
                  method = "MA.criterion", criterion = "AIC", print.time = TRUE)

write_rds(model_ave, paste0(file_path, "Output/imputed_exposure_model_2july2020.rds"))

exposure_model <- read_rds(paste0(file_path, "Output/imputed_exposure_model_2july2020.rds"))

summary(model_ave)

# plot(model_ave) # only used when bootstrap used in mami

print(exposure_model)

# Exponentiate results for manuscript tables
exp_results <- as.data.frame(exposure_model$coefficients.s) %>% 
  rownames_to_column() %>% 
  mutate(estimate = round((exp(Estimate)-1)*100, digits = 2),
         ci_low = round((exp(`Lower CI`)-1)*100, digits = 2),
         ci_hi = round((exp(`Upper CI`)-1)*100, digits = 2)) %>% 
  select(rowname, estimate, ci_low, ci_hi)

exp_results
```

```{r}
# Look at R^2 for final selected model
imputed_exposure_data <- read_rds(paste0(file_path, "Output/imputed_exposure_data_2july2020.rds"))

model_data <- complete(imputed_exposure_data, "long") 

model_results <- lm(log_pm_mean_sampling_period ~
                    income_3level + 
                    residents_smoke +
                    home_floors_2level +
                    home_sqft_2level +
                    stove_age_3level + 
                    chimney_clean_3level + 
                    sums_events_sampling_period_7.5 + 
                    mean_temp_sampling_period_5 + 
                    amb_pm_sampling_period_5 + 
                    stove_grade_3level + 
                    home_fireplace,
                    data = model_data)

summary(model_results)
```



##################### 

Below are other options/ideas for model selection
Not using for now, but keep for resources


```{r, include=FALSE}
full_model <- lm(log(pm_mean_sampling_period) ~ income_3level + 
                 stove_age_3level + home_windows_2level +
                 chimney_clean_3level + wood_collect_2level + 
                 home_act_door + home_act_smoking + home_act_sweep + 
                 stove_grade_3level + moisture_closest_2level + 
                 total_residents_2level + mean_temp_sampling_period_5 +
                 sums_events_sampling_period, 
                 data = analysis_data)


summary(full_model)
r.squaredGLMM(full_model)
tidy(full_model)

plot(full_model)
```


# Best subsets selection using dredge() from MuMIn

Make sure to run `na.exclude` on analysis dataset and `options(na.action = "na.fail")`
before running the dredge best-subsets function below. This will ensure that the 
same dataset is being used for each potential model, which is an assumption and
a prerequisite for comparing different model ranking like AIC.

```{r, eval=FALSE, include=FALSE}
options(na.action = "na.fail")

all_subsets_aic <- dredge(full_model, rank = "AIC", extra = c("R^2"))

all_subsets_aicc <- dredge(full_model, rank = "AICc", extra = c("R^2"))
par(mar = c(3,5,6,4))
plot(all_subsets_aicc)

all_subsets_bic <- dredge(full_model, rank = "BIC", extra = c("R^2"))

write_rds(all_subsets_aic, paste0(output_path, "Output/all_subsets_aic"))
write_rds(all_subsets_aicc, paste0(output_path, "Output/all_subsets_aicc"))
write_rds(all_subsets_bic, paste0(output_path, "Output/all_subsets_bic"))
```

```{r}
all_subsets_aic <- read_rds(paste0(output_path, "Output/all_subsets_aic"))
all_subsets_aicc <- read_rds(paste0(output_path, "Output/all_subsets_aicc"))
all_subsets_bic <- read_rds(paste0(output_path, "Output/all_subsets_bic"))

head(all_subsets_aic, 10)
head(all_subsets_aicc, 10)
head(all_subsets_bic, 10)
```


```{r}
subset_model <- lm(log(pm_mean_sampling_period) ~ 
                   income_3level + home_act_door + residents_smoke, 
                   data = analysis_data)

summary(subset_model)
#tidy(subset_model)

plot(subset_model)
```


Looking at Lasso regression
May be beyond the scope of this paper, but keep code and references:

https://cran.r-project.org/web/packages/MuMIn/MuMIn.pdf 

http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html

https://cran.r-project.org/web/packages/glmnet/glmnet.pdf

https://cran.r-project.org/web/packages/glmmLasso/glmmLasso.pdf

https://arxiv.org/pdf/1306.2427.pdf 

```{r} 
library(MuMIn)
library(leaps)
library(glmnet)
library(glmmLasso)

# Range of lambdas
grid = 10^seq(10, -2, length = 100)

lasso_results <- glmmLasso(log(pm_mean_sampling_period) ~ income_3level + 
                 residents_smoke + stove_age_3level + home_windows_2level +
                 chimney_clean_3level + wood_collect_2level + 
                 home_act_door + home_act_smoking + home_act_sweep + 
                 stove_grade_3level + moisture_closest_2level + 
                 total_residents_2level,
                 rnd = list(area = ~ 1), 
                 lambda = grid,
                 data = analysis_data)

summary(lasso_results)

predict(lasso_results)
```

Looking at Ridge regression:

https://drsimonj.svbtle.com/ridge-regression-with-glmnet

```{r}
ridge_results <- cv.glmnet(x = ind_vars, y = dep_var, alpha = 0)

plot(ridge_results)

opt_lambda <- ridge_results$lambda.min
opt_lambda

fit <- ridge_results$glmnet.fit
summary(fit)

y_predicted <- predict(fit, s = opt_lambda, newx = ind_vars)

# Sum of Squares Total and Error
sst <- sum((dep_var - mean(dep_var))^2)
sse <- sum((y_predicted - dep_var)^2)

# R squared
rsq <- 1 - sse / sst
rsq
```

# Train and test datasets

```{r}
# Random sample indexes
train_index <- sample(1:nrow(adult), 0.8 * nrow(adult))
test_index <- setdiff(1:nrow(adult), train_index)



dep_var <- analysis_data$pm_mean_sampling_period

ind_vars <- analysis_data %>% 
  select(-pm_mean_sampling_period, -area) %>% 
  data.matrix()
```


