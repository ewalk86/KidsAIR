---
title: "KidsAIR: exposure model"
author: "Ethan Walker"
date: "Started 19 March 2020, Updated 16 April 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      eval = TRUE, include = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(readxl)
library(naniar)
library(lubridate)
library(zoo)
library(lme4)
library(lmerTest)
library(pbkrtest)
library(emmeans)
library(broom)
library(MuMIn)
library(leaps)
library(glmnet)
jv_palette <- c("#330099","#CC0066","#FF6633", 
                 "#0099CC", "#FF9900","#CC6633",
                  "#FF3366", "#33CC99", "#33999")
```

```{r}
# Load individual datasets

input_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/KidsAIR/Input/")
output_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/KidsAIR/")
input_file <- c("exposure_analysis_data_long_new.rds")
output_file <- c("exposure_analysis_data_long_new.rds")

exposure_analysis_data_long <- 
  read_rds(paste0(output_path, "Output/exposure_analysis_data_long_new.rds")) 

exposure_analysis_data_medium <- 
  read_rds(paste0(output_path, "Output/exposure_analysis_data_medium.rds")) 

exposure_analysis_data_short <- 
  read_rds(paste0(output_path, "Output/exposure_analysis_data_short.rds"))

sums_rolling_pm_data <- 
  read_rds(paste0(output_path, "Output/sums_rolling_pm_data.rds"))

health_exposure_data_sampling_day <- 
  read_rds(paste0(output_path, "Output/health_exposure_data_sampling_day.rds"))
```

```{r}
# Prep and merge data

####### Format SUMs data to merge with analysis data below
sums_temp_change <- sums_rolling_pm_data %>% 
  filter(winter_id == 1 & treatment == "Placebo") %>% 
  group_by(area, home, sampling_day) %>% 
  distinct(datetime_sums, .keep_all = TRUE) %>% 
  group_by(area, home, sampling_day) %>% 
  mutate(time_diff = (lead(datetime_sums) - datetime_sums)) %>% 
  mutate(lead_temp = if_else(time_diff < 20, lead(temp_c_sums, 4), lead(temp_c_sums)),
         lead_temp = if_else(time_diff > 25, 999, lead_temp)) %>% 
  replace_with_na(replace = list(lead_temp = 999)) %>% 
  mutate(temp_diff = lead_temp - temp_c_sums,
         # change temp in the following line
         temp_diff_check = if_else(temp_diff >= 5, 1, 0),
         heat_event = if_else(temp_diff_check == 1 & lag(temp_diff_check) == 1, 0,
                              temp_diff_check),
         heat_event = if_else(is.na(temp_diff_check), 1,
                              heat_event)) %>% 
  group_by(area, home, sampling_day) %>% 
  mutate(sums_events_sampling_day = sum(heat_event, na.rm = TRUE),
         sums_events_sampling_day_cat = cut(sums_events_sampling_day, 
                                            breaks = c(0, 2, 50),
                           labels = c("<2", "2+"),
                                 right = FALSE)) %>% 
  distinct(sampling_day, .keep_all = TRUE) %>% 
  ungroup() %>% 
  select(area:pm_rolling_20, sums_mean_winter:sums_mean_sampling_period,
         time_diff:sums_events_sampling_day_cat) %>% 
  arrange(area, home, sample_date) %>% 
  group_by(home) %>% 
  mutate(sums_events_sampling_period = mean(sums_events_sampling_day, na.rm = TRUE)) %>% 
  select(area, home, home_winter_id, sums_events_sampling_period) %>% 
  distinct(home, .keep_all = TRUE) %>% 
  ungroup()

####### Format ambient data to merge with analysis data below
ambient_data <- exposure_analysis_data_long %>% 
  filter(winter_id == 1) %>% 
  filter(treatment == "Placebo") %>% 
  #filter(area == "WMT") %>%
  filter(!is.na(sampling_day)) %>% 
  filter(!is.na(sample_date)) %>%
  select(area, home, child_id_char, sample_date, sampling_day, pm_mean_daily,
         zip:mean_temp_roll_4day) %>% 
  group_by(home) %>% 
  mutate(amb_pm_sampling_period_5 = mean(amb_pm_24hr, na.rm = TRUE)/5,
         mean_temp_sampling_period_5 = mean(mean_temp, na.rm = TRUE)/5) %>% 
  distinct(home, .keep_all = TRUE) %>% 
  ungroup()

####### Format home activity data to merge with analysis data below
home_activity_data <- exposure_analysis_data_medium %>% 
  filter(treatment == "Placebo") %>% 
  #filter(winter_id == 1) %>% 
  select(home, area, home_winter_id, sampling_day, starts_with("home_act")) %>% 
  group_by(area, home, home_winter_id) %>% 
  distinct(sampling_day, .keep_all = TRUE) %>% 
  group_by(area, home, home_winter_id) %>% 
  mutate_at(vars(starts_with("home_act")), as.numeric) %>% 
  mutate_at(vars(starts_with("home_act")), funs(. - 1)) %>% 
  mutate_at(vars(starts_with("home_act")), funs(sum(.))) %>% 
  mutate_at(vars(starts_with("home_act")), factor) %>%
  ungroup() %>% 
  distinct(area, home,  home_winter_id, .keep_all = TRUE) 

####### Format full data to use for analysis
analysis_data <- exposure_analysis_data_short %>% 
  filter(winter_id == 1) %>% 
  filter(treatment == "Placebo") %>% 
  #filter(area == "WMT") %>% 
  group_by(area, home) %>% 
  distinct(home, winter_id, .keep_all = TRUE) %>% 
  ungroup() %>% 
  mutate(moisture_closest_2level = cut(moisture_closest, breaks = c(0, 10.5, 100),
                                 labels = c("<10.5", "10.5+"),
                                 right = FALSE),
         moisture_winter_2level = cut(mean_moisture_winter, breaks = c(0, 10.5, 100),
                                 labels = c("<10.5", "10.5+"),
                                 right = FALSE)) %>% 
  mutate(temp_max_2level = cut(temp_indoor_max, breaks = c(0, 30, 100),
                                 labels = c("<30", "30+"),
                                 right = FALSE),
         temp_min_2level = cut(temp_indoor_min, breaks = c(0, 16.5, 100),
                                 labels = c("<16.5", "16.5+"),
                                 right = FALSE),
         rh_max_2level = cut(rh_indoor_max, breaks = c(0, 40, 100),
                                 labels = c("<40", "40+"),
                                 right = FALSE),
         rh_min_2level = cut(rh_indoor_min, breaks = c(0, 20, 100),
                                 labels = c("<20", "20+"),
                                 right = FALSE)) %>% 
  mutate(sums_mean_sampling_period_5 = sums_mean_sampling_period/5,
         temp_perc_25_2level = cut(temp_perc_25, breaks = c(0, 50, 100),
                                 labels = c("<50", "50+"),
                                 right = FALSE),
         temp_perc_27_2level = cut(temp_perc_27, breaks = c(0, 35, 100),
                                 labels = c("<35", "35+"),
                                 right = FALSE),
         temp_perc_30_2level = cut(temp_perc_30, breaks = c(0, 10, 100),
                                 labels = c("<10", "10+"),
                                 right = FALSE)) %>% 
  group_by(home) %>% 
  mutate(residents_smoke = if_else(winter_id == 1 & is.na(residents_smoke),
                                   lead(residents_smoke), residents_smoke)) %>% 
  ungroup() %>% 
  left_join(sums_temp_change, by = c("area", "home", "home_winter_id")) %>% 
  left_join(ambient_data, by = c("area", "home")) %>% 
  select(-starts_with("home_act")) %>% 
  left_join(home_activity_data, by = c("area", "home", "home_winter_id")) %>% 
  replace_with_na(replace = list(mean_temp_sampling_period_5 = "NaN")) 
```

Initial variables to use for model selection (14) from collinearity RMD:
Demographics: area, income_3level, residents_smoke
Home Characteristics: home_floors_2level, stove_age_3level,
                      chimney_clean_3level, home_mold, wood_collect_2level
Home Activity: home_act_door, home_act_smoking, home_act_sweep
Others: sums_events_sampling_period, mean_temp_sampling_period_5, 
        stove_grade_3level, moisture_closest_2level,

Note: sums_events_sampling_period and mean_temp_sampling_period_5 have a lot of
missing data and reduce the sample size from 93 to 43. Not considering these
variables for model selection for now.

Also try adding other variables in to check their impact on model selection:
   total_residents_2level (seems impactful), home_type_2level (not impactful), 
   home_windows_2level (seems impactful), home_act_windows (not very impactful),
   education_3level (not impactful)
   
Some vars not important in any models, so removing from consideration:
   home_mold, home_floors_2level, home_act_windows, home_type_2level
   
Next steps:
Some vars (like residents_smoke), other demographics, and home activity vars
have quite a bit of missing data. This is in addition to the missing ambient
and SUMs data. The first step should be to account for as much of this as possible.
See if there are ways to pull demographic data from Winter 2.
Then, see if data for WMT is more complete in general. The idea is to minimize
missing data for model selection and the final model to have as much power as
possible. 
Consider doing a more "full" model for WMT only (if there is less missing data),
particularly since the ambient data is more reliable for WMT than the other areas.
Then you could justify not doing a mixed model, and model selection would be easier.
Then, using data from all areas, use the full model from WMT to work on a 
mixed model that is likely reduced due to sparse data from the other areas.
Since model selection is difficult with mixed models, use the WMT model to inform
this model, while also doing sensitivity analysis to check other variables.
Aside from the multivariable model, much of the paper could also be looking at
simple associations between PM and some of the novel covars (SUMS, ambient data,
stove grades, wood moisture), as well as methods for collecting and analysing 
those vars.
Also look into predict() function for teach/test and validating the model.
Discussion can focus on what important predictors of indoor PM are in these homes - 
if simple demographic data predicts as well as complex things like SUMs and wood
moisture, or if there is a spectrum of predictors and complexity in their collection.

```{r, include=FALSE}
full_model <- lm(log(pm_mean_sampling_period) ~ income_3level + 
                 stove_age_3level + home_windows_2level +
                 chimney_clean_3level + wood_collect_2level + 
                 home_act_door + home_act_smoking + home_act_sweep + 
                 stove_grade_3level + moisture_closest_2level + 
                 total_residents_2level + mean_temp_sampling_period_5 +
                 sums_events_sampling_period, 
                 data = analysis_data)


summary(full_model)
r.squaredGLMM(full_model)
tidy(full_model)

plot(full_model)
```


# Best subsets selection using dredge() from MuMIn

Make sure to run `na.exclude` on analysis dataset and `options(na.action = "na.fail")`
before running the dredge best-subsets function below. This will ensure that the 
same dataset is being used for each potential model, which is an assumption and
a prerequisite for comparing different model ranking like AIC.

```{r, eval=FALSE, include=FALSE}
options(na.action = "na.fail")

all_subsets_aic <- dredge(full_model, rank = "AIC", extra = c("R^2"))

all_subsets_aicc <- dredge(full_model, rank = "AICc", extra = c("R^2"))
par(mar = c(3,5,6,4))
plot(all_subsets_aicc)

all_subsets_bic <- dredge(full_model, rank = "BIC", extra = c("R^2"))

write_rds(all_subsets_aic, paste0(output_path, "Output/all_subsets_aic"))
write_rds(all_subsets_aicc, paste0(output_path, "Output/all_subsets_aicc"))
write_rds(all_subsets_bic, paste0(output_path, "Output/all_subsets_bic"))
```

```{r}
all_subsets_aic <- read_rds(paste0(output_path, "Output/all_subsets_aic"))
all_subsets_aicc <- read_rds(paste0(output_path, "Output/all_subsets_aicc"))
all_subsets_bic <- read_rds(paste0(output_path, "Output/all_subsets_bic"))

head(all_subsets_aic, 10)
head(all_subsets_aicc, 10)
head(all_subsets_bic, 10)
```


```{r}
subset_model <- lm(log(pm_mean_sampling_period) ~ 
                   income_3level + home_act_door + residents_smoke, 
                   data = analysis_data)

summary(subset_model)
#tidy(subset_model)

plot(subset_model)
```


#####################


Looking at Lasso regression
May be beyond the scope of this paper, but keep code and references:

https://cran.r-project.org/web/packages/MuMIn/MuMIn.pdf 

http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html

https://cran.r-project.org/web/packages/glmnet/glmnet.pdf

https://cran.r-project.org/web/packages/glmmLasso/glmmLasso.pdf

https://arxiv.org/pdf/1306.2427.pdf 

```{r} 
library(MuMIn)
library(leaps)
library(glmnet)
library(glmmLasso)

# Range of lambdas
grid = 10^seq(10, -2, length = 100)

lasso_results <- glmmLasso(log(pm_mean_sampling_period) ~ income_3level + 
                 residents_smoke + stove_age_3level + home_windows_2level +
                 chimney_clean_3level + wood_collect_2level + 
                 home_act_door + home_act_smoking + home_act_sweep + 
                 stove_grade_3level + moisture_closest_2level + 
                 total_residents_2level,
                 rnd = list(area = ~ 1), 
                 lambda = grid,
                 data = analysis_data)

summary(lasso_results)

predict(lasso_results)
```

Looking at Ridge regression:

https://drsimonj.svbtle.com/ridge-regression-with-glmnet

```{r}
ridge_results <- cv.glmnet(x = ind_vars, y = dep_var, alpha = 0)

plot(ridge_results)

opt_lambda <- ridge_results$lambda.min
opt_lambda

fit <- ridge_results$glmnet.fit
summary(fit)

y_predicted <- predict(fit, s = opt_lambda, newx = ind_vars)

# Sum of Squares Total and Error
sst <- sum((dep_var - mean(dep_var))^2)
sse <- sum((y_predicted - dep_var)^2)

# R squared
rsq <- 1 - sse / sst
rsq
```

# Train and test datasets

```{r}
# Random sample indexes
train_index <- sample(1:nrow(adult), 0.8 * nrow(adult))
test_index <- setdiff(1:nrow(adult), train_index)



dep_var <- analysis_data$pm_mean_sampling_period

ind_vars <- analysis_data %>% 
  select(-pm_mean_sampling_period, -area) %>% 
  data.matrix()
```


Looking at model selection and averaging after multiple imputation

Helpful manuals and vignettes:

https://cran.r-project.org/web/packages/mice/mice.pdf

```{r}
library(mice)

# Select analysis vars
selected_vars <- analysis_data %>% 
  select(area, pm_mean_sampling_period, income_3level, residents_smoke, 
         stove_age_3level, home_windows_2level,
         chimney_clean_3level, wood_collect_2level,
         home_act_door, home_act_sweep, home_act_windows, 
         sums_events_sampling_period, mean_temp_sampling_period_5, 
         stove_grade_3level, moisture_closest_2level) %>% 
  mutate(home_act_door = factor(home_act_door, levels = c(0,1,2,3,4,5,6)),
         home_act_sweep = factor(home_act_sweep, levels = c(0,1,2,3,4,5,6)),
         home_act_windows = factor(home_act_windows, levels = c(0,1,2,3,4,5,6)),
         area = factor(area, levels = c("AK", "NN", "WMT")))
  
# Check % missing data
mean(is.na(selected_vars))

# Using mice package

# Look for patterns in missing data
md.pattern(selected_vars)



# Impute missing data; m = 20 datasets (check % missing data and match)
imputed_data <- mice(selected_vars, m=5,
                     method = c("polyreg", "pmm", "polr", "logreg", "polr",
                                "logreg", "polr", "logreg", "polr", "polr",
                                "polr", "pmm", "pmm", "polr", "logreg"))

summary(imputed_data)

# Can add "long" or "broad arguments
complete(imputed_data, "long")

# Sample one of the imputed datasets
check1 <- complete(imputed_data, 3)

densityplot(selected_vars$pm_mean_sampling_period)

# Use seed to get the exact same results from random sampling
# seed = 123

# See vignette #2 for setting up predictor matrices and relationships b/w vars

# Check for convergence
## In general, we would like the streams to intermingle and be free of any trends 
## at the later iterations.
plot(imputed_data)

# Check that the imputation method matches the data type correctly
## particularly for PM that should be log transformed, and the factors

stripplot(imputed_data)

# Can do regression on the imputed data - either pooled or individual datasets

```

http://mami.r-forge.r-project.org/MAMI_manual.pdf 

```{r}
library(MAMI)


# Using MAMI package, perform model averaging and selection
model_ave <- mami(imputed_data, missing.data = "imputed", model = "gaussian",
                  outcome = "pm_mean_sampling_period", 
                  method = "MA.criterion", criterion = "AIC", print.time = TRUE,
                  add.transformation = c("log(pm_mean_sampling_period)"))


                  #inference = "+boot", B = 2, X.org = selected_vars

summary(model_ave)
plot(model_ave)
```

